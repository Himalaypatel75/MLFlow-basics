# MLFlow Basics

## Overview

This guide provides a brief introduction to using MLFlow for tracking and displaying model performance metrics, including accuracy, recall (for class 0 and class 1), and macro F1 score. MLFlow is a versatile tool that simplifies the process of managing machine learning experiments.

## How to Use MLFlow

1. **Track Metrics:** MLFlow allows you to log various performance metrics such as accuracy, recall for different classes, and macro F1 score. This helps in evaluating and comparing different models effectively.

2. **Display Metrics:** Once metrics are logged, you can visualize them on the MLFlow dashboard to gain insights into your model's performance.

## Visualization

1. **Comparison Report:** The comparison report provides a side-by-side view of different models and their performance metrics. This is useful for analyzing and selecting the best model based on your criteria.

   ![Comparison Report](https://github.com/Himalaypatel75/MLFlow-basics/blob/main/screencapture-127-0-0-1-5000-2024-08-30-20_05_51.png)

2. **Experiments Home Page:** The experiments home page gives an overview of all experiments, including metrics, parameters, and artifacts associated with each run.

   ![Experiments Home Page](https://github.com/Himalaypatel75/MLFlow-basics/blob/main/screencapture-127-0-0-1-5000-2024-08-30-18_19_32.png)

For more detailed information and advanced features, refer to the MLFlow documentation.